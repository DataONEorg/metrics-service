"""

Script to keep the ES eventlog index upto date with the aggregated objects like -
DataONE portal objects, DataONE User profiles, etc...

Note: This script needs Python 3.6 or higher.

"""

import os
import re
import sys
import json
import asyncio
import logging
import argparse
import datetime
import requests
import concurrent.futures


from d1_metrics import common
from d1_metrics import solrclient
from d1_metrics import metricselasticsearch


DATAONE_CN_SOLR = [
    "https://cn.dataone.org/cn/v2/query/solr/"
]

DATAONE_MN_SOLR = [
    "https://arcticdata.io/metacat/d1/mn/v2/query/solr/",
    "https://knb.ecoinformatics.org/knb/d1/mn/v2/query/solr/",
]

CONCURRENT_REQUESTS = 20  # max number of concurrent requests to run

ZERO = datetime.timedelta(0)

BATCH_TDELTA_PERIOD = datetime.timedelta(minutes=10)


# ==========


def getModifiedPortals():
    """
    Queries Solr to get the list of portals that were modified
    :return:
    """
    pass


def performRegularPortalChecks():
    """
    Checks for newly added datasets that satisfy the collection query
    associated with this portal
    :return:
    """
    pass


def getPortalMetadata():
    """
    Retrieves portal attributes from solr
    :return:
    """
    pass


def resolvePortalCollectionQuery():
    """

    :return:
    """
    pass


def retrievePortalDatasetIdentifierFamily():
    """

    :return:
    """
    pass


def generatePortalHash():
    """
    Generates hash for a given Portal from list of identifiers
    :return:
    """
    pass


def storePortalHash():
    """
    Stores portal hash in the database
    :return:
    """
    pass


def getPIDRecords():
    """
    Queries ES and retrieves records from the index for a given PID
    :return:
    """
    metrics_elastic_search = MetricsElasticSearch()
    metrics_elastic_search.connect()


def testSetUP():
    """
    Temporary fixture to test the functionalities
    :return:
    """
    test_fixture = {}

    # Just a random test pid from eventlog-0 index
    test_fixture["PID"] = "aekos.org.au/collection/sa.gov.au/bdbsa_veg/survey_88.20160201"
    return test_fixture


def main():
    parser = argparse.ArgumentParser(
        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "-l",
        "--log_level",
        action="count",
        default=0,
        help="Set logging level, multiples for more detailed.",
    )
    parser.add_argument(
        "-t",
        "--test",
        default=False,
        action="store_true",
        help="Show the starting point and number of records to retrieve but don't download.",
    )
    parser.add_argument(
        "-E", "--enddate", default=None, help="End date. If not set then now is used."
    )

    args = parser.parse_args()
    # Setup logging verbosity
    levels = [logging.WARNING, logging.INFO, logging.DEBUG]
    level = levels[min(len(levels) - 1, args.log_level)]

    end_date = args.enddate

    if end_date is None:
        # end_date = start_date + BATCH_TDELTA_PERIOD
        end_date = datetime.datetime.utcnow()
    else:
        end_date = datetime.datetime.strptime(end_date, "%Y-%m-%dT%H:%M:%S")

    return


if __name__ == "__main__":
    sys.exit(main())